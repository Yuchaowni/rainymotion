{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pysteps configuration file found at: /Users/jiang/anaconda3/envs/rainymotion/lib/python3.7/site-packages/pysteps/pystepsrc\n",
      "\n",
      "--------------- using these files ---------------\n",
      "/Users/jiang/data/kakuho_dev/202002270435.prec.ints.1km.bin\n",
      "/Users/jiang/data/kakuho_dev/202002270440.prec.ints.1km.bin\n",
      "/Users/jiang/data/kakuho_dev/202002270445.prec.ints.1km.bin\n",
      "/Users/jiang/data/kakuho_dev/202002270545.prec.ints.1km.bin\n",
      "--------------- now time is: ---------------\n",
      "2020-02-27 04:45:00\n",
      "(3, 3360, 2560) (2, 3360, 2560)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(<function decomposition_fft at 0x136bf0dd0>, <function recompose_fft at 0x136c22d40>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e76ac8fdd037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mR_thr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmperpixel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_seperation_in_minute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecomp_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fft\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mbandpass_filter_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gaussian\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nonparametric\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvel_pert_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bps\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     mask_method=\"incremental\", seed=seed)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Back-transform to rain rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github_all/rainymotion/pysteps_plus.py\u001b[0m in \u001b[0;36mforecast12\u001b[0;34m(R, V, n_timesteps, n_ens_members, n_cascade_levels, R_thr, kmperpixel, timestep, extrap_method, decomp_method, bandpass_filter_method, noise_method, noise_stddev_adj, ar_order, vel_pert_method, conditional, probmatching_method, mask_method, callback, return_output, seed, num_workers, fft_method, measure_time)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_order\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecomp_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mR_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMASK_thr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mR_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "# written by Yuchao Jiang on 2020.3.3\n",
    "# use rainymotion library, only make one prediction for the next one hour\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from datetime import datetime,timedelta\n",
    "from rainymotion import models, metrics, utils\n",
    "from time import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.ma as ma\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import joblib \n",
    "import pysteps_plus\n",
    "from pysteps.motion.lucaskanade import dense_lucaskanade\n",
    "\n",
    "t0 = time()\n",
    "#print(os.getcwd())\n",
    "data_folder = \"/Users/jiang/data/kakuho_dev\"  ## in local computer \n",
    "output_folder = \"./output_vector\"\n",
    "if not os.path.exists(data_folder):\n",
    "\tdata_folder = \"../../../usr/amoeba/pub/rain_kakuho/hres.jma_nowcast/out\"\n",
    "bin_files = glob.glob(os.path.join(data_folder,\"*ints.1km.bin\"))  # 288 = 12*24\n",
    "bin_files.sort()\n",
    "now_files = bin_files[-15:-12]\n",
    "truth_file = bin_files[-1]\n",
    "print(\"--------------- using these files ---------------\")\n",
    "print(*now_files, sep = \"\\n\")\n",
    "print(truth_file)\n",
    "\n",
    "datetime_str = now_files[-1].split(\"/\")[-1].split(\".\")[0]\n",
    "datetime_object = datetime.strptime(datetime_str,\"%Y%m%d%H%M\")\n",
    "print(\"--------------- now time is: ---------------\")\n",
    "print(datetime_object)\n",
    "\n",
    "threshold = 0.1\n",
    "zerovalue = -15.0\n",
    "n_ens_members = 10\n",
    "time_seperation_in_minute = 5 \n",
    "seed = 24\n",
    "p_threshold = 0.5 # probability threshold\n",
    "\n",
    "inputs = np.zeros(shape = (3,3360,2560), dtype = np.float32)\n",
    "for i, bin_file in enumerate(now_files):\n",
    "\tinputs[i] = np.fromfile(bin_file, dtype = \"float32\").reshape((3360,2560))\n",
    "mask = inputs[0] < 0\n",
    "# inputs[inputs < 0] = 0\n",
    "zeros = inputs < threshold\n",
    "inputs[~zeros] = 10.0 * np.log10(inputs [~zeros] )\n",
    "inputs[zeros] = zerovalue\n",
    "V = dense_lucaskanade(inputs)\n",
    "print(inputs.shape, V.shape)\n",
    "print(type(inputs), type(V))\n",
    "R_f = pysteps_plus.forecast12(inputs, V, n_timesteps = 12, n_ens_members=n_ens_members, n_cascade_levels=6, \n",
    "    R_thr=-10.0, kmperpixel=2.0, timestep = time_seperation_in_minute, decomp_method=\"fft\",\n",
    "    bandpass_filter_method=\"gaussian\", noise_method=\"nonparametric\", vel_pert_method=\"bps\",\n",
    "    mask_method=\"incremental\", seed=seed)\n",
    "\n",
    "# Back-transform to rain rates\n",
    "R_f = transformation.dB_transform(R_f, threshold=-10.0, inverse=True)[0]  # (20, 1000,1000)\n",
    "# compute the exceedance probability of 0.1 mm/h from the ensemble\n",
    "P_f = ensemblestats.excprob(R_f, threshold, ignore_nan=True) \n",
    "   \n",
    "gt_in_60_min = np.fromfile(truth_file, dtype = \"float32\").reshape((3360,2560))\n",
    "\n",
    "hits   = np.sum(np.logical_and(P_f >= p_threshold, gt_in_60_min >= threshold))    \n",
    "misses = np.sum(np.logical_and(P_f <  p_threshold, gt_in_60_min >= threshold))  \n",
    "false_alarms = np.sum(np.logical_and(P_f >= p_threshold, gt_in_60_min < threshold))\n",
    "threat = hits/(hits + false_alarms + misses)\n",
    "\n",
    "print(\"--------------- Result: ---------------\")\n",
    "print(f\"rain coverage = {np.sum(gt_in_60_min>= threshold)/np.sum(~mask):.3f}\")\n",
    "print(f\"threat = {threat:.2f}\")\n",
    "print(f\"time cost: {time()-t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pysteps.motion.lucaskanade import dense_lucaskanade\n",
    "from pysteps.nowcasts.steps import _compute_incremental_mask,_check_inputs,_compute_sprog_mask\n",
    "from pysteps import cascade, extrapolation, noise, utils\n",
    "from pysteps.postprocessing import probmatching\n",
    "from pysteps.timeseries import autoregression, correlation\n",
    "from pysteps.nowcasts import utils as nowcast_utils\n",
    "import scipy.ndimage\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "def forecast12(R, V, n_timesteps, n_ens_members=24, n_cascade_levels=6,\n",
    "             R_thr=None, kmperpixel=None, timestep=None,\n",
    "             extrap_method=\"semilagrangian\", decomp_method=\"fft\",\n",
    "             bandpass_filter_method=\"gaussian\", noise_method=\"nonparametric\",noise_stddev_adj=None, \n",
    "             ar_order=2, vel_pert_method=\"bps\",\n",
    "             conditional=False, probmatching_method=\"cdf\",\n",
    "             mask_method=\"incremental\", callback=None, return_output=True,\n",
    "             seed=None, num_workers=1, fft_method=\"numpy\",  measure_time=False):\n",
    "\n",
    "    filter_kwargs = dict()\n",
    "    noise_kwargs = dict()\n",
    "    extrap_kwargs = dict()\n",
    "\n",
    "    if vel_pert_method == \"bps\":\n",
    "        vp_par  = noise.motion.get_default_params_bps_par()\n",
    "        vp_perp = noise.motion.get_default_params_bps_perp()\n",
    "\n",
    "    num_ensemble_workers = n_ens_members if num_workers > n_ens_members else num_workers\n",
    "    fft = utils.get_method(fft_method, shape=R.shape[1:], n_threads=num_workers)\n",
    "    M, N = R.shape[1:]\n",
    "\n",
    "    # initialize the band-pass filter\n",
    "    filter_method = cascade.get_method(bandpass_filter_method)\n",
    "    filter = filter_method((M, N), n_cascade_levels, **filter_kwargs)\n",
    "    decomp_method = cascade.get_method(decomp_method)\n",
    "    extrapolator_method = extrapolation.get_method(extrap_method)\n",
    "    x_values, y_values = np.meshgrid(np.arange(R.shape[2]),np.arange(R.shape[1]))\n",
    "    xy_coords = np.stack([x_values, y_values])\n",
    "    R = R[-(ar_order + 1):, :, :].copy()\n",
    "    MASK_thr = None\n",
    "\n",
    "    # advect the previous precipitation fields to the same position with the\n",
    "    # most recent one (i.e. transform them into the Lagrangian coordinates)\n",
    "    extrap_kwargs = dict()\n",
    "    extrap_kwargs['xy_coords'] = xy_coords\n",
    "    res = list()\n",
    "\n",
    "    for i in range(ar_order):  # 2\n",
    "        R[i, :, :] = extrapolator_method(R[i, :, :], V, ar_order - i,\"min\", **extrap_kwargs)[-1]\n",
    "\n",
    "    # get methods for perturbations\n",
    "    init_noise, generate_noise = noise.get_method(noise_method)\n",
    "    # initialize the perturbation generator for the precipitation field\n",
    "    pp = init_noise(R, fft_method=fft, **noise_kwargs)\n",
    "    noise_std_coeffs = np.ones(n_cascade_levels)\n",
    "\n",
    "    # compute the cascade decompositions of the input precipitation fields\n",
    "    R_d = []\n",
    "    for i in range(ar_order + 1):\n",
    "        print(decomp_method)\n",
    "        R_ = decomp_method(R[i, :, :], filter, MASK=MASK_thr, fft_method=fft)\n",
    "        R_d.append(R_)\n",
    "\n",
    "    # normalize the cascades and rearrange them into a four-dimensional array\n",
    "    # of shape (n_cascade_levels,ar_order+1,m,n) for the autoregressive model\n",
    "    R_c, mu, sigma = nowcast_utils.stack_cascades(R_d, n_cascade_levels)\n",
    "    R_d = None\n",
    "\n",
    "    # compute lag-l temporal autocorrelation coefficients for each cascade level\n",
    "    GAMMA = np.empty((n_cascade_levels, ar_order))\n",
    "    for i in range(n_cascade_levels):\n",
    "        R_c_ = np.stack([R_c[i, j, :, :] for j in range(ar_order + 1)])\n",
    "        GAMMA[i, :] = correlation.temporal_autocorrelation(R_c_, MASK=MASK_thr)\n",
    "    R_c_ = None\n",
    "\n",
    "    # adjust the lag-2 correlation coefficient to ensure that the AR(p) process is stationary\n",
    "    for i in range(n_cascade_levels):\n",
    "        GAMMA[i, 1] = autoregression.adjust_lag2_corrcoef2(GAMMA[i, 0], GAMMA[i, 1])\n",
    "\n",
    "    # estimate the parameters of the AR(p) model from the autocorrelation coefficients\n",
    "    PHI = np.empty((n_cascade_levels, ar_order + 1))\n",
    "    for i in range(n_cascade_levels):\n",
    "        PHI[i, :] = autoregression.estimate_ar_params_yw(GAMMA[i, :])\n",
    "        \n",
    "    # discard all except the p-1 last cascades because they are not needed for the AR(p) model\n",
    "    R_c = R_c[:, -ar_order:, :, :]\n",
    "\n",
    "    # stack the cascades into a five-dimensional array containing all ensemble members\n",
    "    R_c = np.stack([R_c.copy() for i in range(n_ens_members)])\n",
    "\n",
    "    # initialize the random generators\n",
    "    randgen_prec = []\n",
    "    randgen_motion = []\n",
    "    np.random.seed(seed)\n",
    "    for j in range(n_ens_members):\n",
    "        rs = np.random.RandomState(seed)\n",
    "        randgen_prec.append(rs)\n",
    "        seed = rs.randint(0, high=1e9)\n",
    "        rs = np.random.RandomState(seed)\n",
    "        randgen_motion.append(rs)\n",
    "        seed = rs.randint(0, high=1e9)\n",
    "\n",
    "    init_vel_noise, generate_vel_noise = noise.get_method(vel_pert_method)\n",
    "    # initialize the perturbation generators for the motion field\n",
    "    vps = []\n",
    "    for j in range(n_ens_members):\n",
    "        kwargs = {\"randstate\": randgen_motion[j], \"p_par\": vp_par, \"p_perp\": vp_perp}\n",
    "        vp_ = init_vel_noise(V, 1. / kmperpixel, timestep, **kwargs)\n",
    "        vps.append(vp_)\n",
    "\n",
    "    D = [None for j in range(n_ens_members)] # very important, store locations of last time step\n",
    "    res = np.zeros(shape = (n_ens_members,V.shape[1], V.shape[2]),dtype = 'float32')\n",
    "\n",
    "    MASK_prec = R[-1, :, :] >= R_thr\n",
    "    # get mask parameters\n",
    "    mask_rim =  10\n",
    "    mask_f =  1\n",
    "    # initialize the structuring element\n",
    "    struct = scipy.ndimage.generate_binary_structure(2, 1)\n",
    "    # iterate it to expand it nxn\n",
    "    n = mask_f * timestep / kmperpixel\n",
    "    struct = scipy.ndimage.iterate_structure(struct, int((n - 1) / 2.))\n",
    "    # initialize precip mask for each member\n",
    "    MASK_prec = _compute_incremental_mask(MASK_prec, struct, mask_rim)\n",
    "    MASK_prec = [MASK_prec.copy() for j in range(n_ens_members)]\n",
    "\n",
    "    fft_objs = []\n",
    "    for i in range(n_ens_members):\n",
    "        fft_objs.append(utils.get_method(fft_method, shape=R.shape[1:]))\n",
    "\n",
    "    R = R[-1, :, :]\n",
    "    #print(\"Starting nowcast computation.\")\n",
    "    # iterate each time step\n",
    "    for t in range(n_timesteps):\n",
    "        sys.stdout.flush()\n",
    "        # iterate each ensemble member\n",
    "        for j in range(n_ens_members):\n",
    "            # generate noise field\n",
    "            EPS = generate_noise(pp, randstate=randgen_prec[j],fft_method=fft_objs[j])\n",
    "            # decompose the noise field into a cascade\n",
    "            EPS = decomp_method(EPS, filter, fft_method=fft_objs[j])\n",
    "\n",
    "            # iterate the AR(p) model for each cascade level\n",
    "            for i in range(n_cascade_levels):\n",
    "                # normalize the noise cascade\n",
    "                EPS_ = (EPS[\"cascade_levels\"][i, :, :] - EPS[\"means\"][i]) / EPS[\"stds\"][i]\n",
    "                EPS_ *= noise_std_coeffs[i]\n",
    "                R_c[j, i, :, :, :] = autoregression.iterate_ar_model(R_c[j, i, :, :, :], PHI[i, :], EPS=EPS_)\n",
    "            del EPS, EPS_ \n",
    "\n",
    "            # compute the recomposed precipitation field(s) from the cascades obtained from the AR(p) model(s)\n",
    "            R_c_ = nowcast_utils.recompose_cascade(R_c[j, :, -1, :, :], mu, sigma)\n",
    "\n",
    "            # apply the precipitation mask to prevent generation of new precipitation into areas where it was not originally observed\n",
    "            R_cmin = R_c_.min()\n",
    "            R_c_ = R_cmin + (R_c_ - R_cmin) * MASK_prec[j]\n",
    "            MASK_prec_ = R_c_ > R_cmin\n",
    "\n",
    "            # Set to min value outside of mask\n",
    "            R_c_[~MASK_prec_] = R_cmin\n",
    "            # adjust the CDF of the forecast to match the most recently observed precipitation field\n",
    "            R_c_ = probmatching.nonparam_match_empirical_cdf(R_c_, R)\n",
    "            MASK_prec[j] = _compute_incremental_mask(R_c_ >= R_thr, struct, mask_rim)\n",
    "\n",
    "            # compute the perturbed motion field\n",
    "            V_ = V + generate_vel_noise(vps[j], (t + 1) * timestep)\n",
    "            # advect the recomposed precipitation field to obtain the forecast for time step t\n",
    "            extrap_kwargs.update({\"D_prev\": D[j], \"return_displacement\": True})\n",
    "            R_f_, D_ = extrapolator_method(R_c_, V_, 1, **extrap_kwargs)\n",
    "            D[j] = D_   # very important for next time step calculation\n",
    "            if t == n_timesteps -1:\n",
    "                res[j] = R_f_[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<function decomposition_fft at 0x136bf0dd0>, <function recompose_fft at 0x136c22d40>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-981fff186933>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mR_thr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmperpixel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecomp_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fft\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbandpass_filter_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gaussian\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nonparametric\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvel_pert_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bps\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     mask_method=\"incremental\", seed=seed)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-7e3b9d85a9c3>\u001b[0m in \u001b[0;36mforecast12\u001b[0;34m(R, V, n_timesteps, n_ens_members, n_cascade_levels, R_thr, kmperpixel, timestep, extrap_method, decomp_method, bandpass_filter_method, noise_method, noise_stddev_adj, ar_order, vel_pert_method, conditional, probmatching_method, mask_method, callback, return_output, seed, num_workers, fft_method, measure_time)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_order\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecomp_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mR_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMASK_thr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mR_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "n_leadtimes = 12\n",
    "n_ens_members = 5\n",
    "timestep = 5   # min, for ensemble model\n",
    "R_f = forecast12(inputs, V, n_leadtimes, n_ens_members, n_cascade_levels=6, \n",
    "    R_thr=-10.0, kmperpixel=2.0, timestep=timestep, decomp_method=\"fft\",\n",
    "    bandpass_filter_method=\"gaussian\", noise_method=\"nonparametric\", vel_pert_method=\"bps\",\n",
    "    mask_method=\"incremental\", seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "R= inputs\n",
    "n_timesteps = n_leadtimes\n",
    "n_ens_members=24\n",
    "n_cascade_levels=6\n",
    "R_thr=None\n",
    "kmperpixel=None\n",
    "timestep=None\n",
    "extrap_method=\"semilagrangian\"\n",
    "decomp_method=\"fft\"\n",
    "bandpass_filter_method=\"gaussian\"\n",
    "noise_method=\"nonparametric\"\n",
    "noise_stddev_adj=None\n",
    "ar_order=2\n",
    "vel_pert_method=\"bps\"\n",
    "conditional=False\n",
    "probmatching_method=\"cdf\"\n",
    "mask_method=\"incremental\"\n",
    "callback=None\n",
    "return_output=True\n",
    "seed=None\n",
    "num_workers=1\n",
    "fft_method=\"numpy\"\n",
    "measure_time=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<function decomposition_fft at 0x136bf0dd0>, <function recompose_fft at 0x136c22d40>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-20e2f95edcf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar_order\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecomp_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mR_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMASK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMASK_thr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mR_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "filter_kwargs = dict()\n",
    "noise_kwargs = dict()\n",
    "extrap_kwargs = dict()\n",
    "\n",
    "if vel_pert_method == \"bps\":\n",
    "    vp_par  = noise.motion.get_default_params_bps_par()\n",
    "    vp_perp = noise.motion.get_default_params_bps_perp()\n",
    "\n",
    "num_ensemble_workers = n_ens_members if num_workers > n_ens_members else num_workers\n",
    "fft = utils.get_method(fft_method, shape=R.shape[1:], n_threads=num_workers)\n",
    "M, N = R.shape[1:]\n",
    "\n",
    "# initialize the band-pass filter\n",
    "filter_method = cascade.get_method(bandpass_filter_method)\n",
    "filter = filter_method((M, N), n_cascade_levels, **filter_kwargs)\n",
    "decomp_method = cascade.get_method(decomp_method)\n",
    "extrapolator_method = extrapolation.get_method(extrap_method)\n",
    "x_values, y_values = np.meshgrid(np.arange(R.shape[2]),np.arange(R.shape[1]))\n",
    "xy_coords = np.stack([x_values, y_values])\n",
    "R = R[-(ar_order + 1):, :, :].copy()\n",
    "MASK_thr = None\n",
    "\n",
    "# advect the previous precipitation fields to the same position with the\n",
    "# most recent one (i.e. transform them into the Lagrangian coordinates)\n",
    "extrap_kwargs = dict()\n",
    "extrap_kwargs['xy_coords'] = xy_coords\n",
    "res = list()\n",
    "\n",
    "for i in range(ar_order):  # 2\n",
    "    R[i, :, :] = extrapolator_method(R[i, :, :], V, ar_order - i,\"min\", **extrap_kwargs)[-1]\n",
    "\n",
    "# get methods for perturbations\n",
    "init_noise, generate_noise = noise.get_method(noise_method)\n",
    "# initialize the perturbation generator for the precipitation field\n",
    "pp = init_noise(R, fft_method=fft, **noise_kwargs)\n",
    "noise_std_coeffs = np.ones(n_cascade_levels)\n",
    "\n",
    "# compute the cascade decompositions of the input precipitation fields\n",
    "R_d = []\n",
    "for i in range(ar_order + 1):\n",
    "    print(decomp_method)\n",
    "    R_ = decomp_method(R[i, :, :], filter, MASK=MASK_thr, fft_method=fft)\n",
    "    R_d.append(R_)\n",
    "\n",
    "# normalize the cascades and rearrange them into a four-dimensional array\n",
    "# of shape (n_cascade_levels,ar_order+1,m,n) for the autoregressive model\n",
    "R_c, mu, sigma = nowcast_utils.stack_cascades(R_d, n_cascade_levels)\n",
    "R_d = None\n",
    "\n",
    "# compute lag-l temporal autocorrelation coefficients for each cascade level\n",
    "GAMMA = np.empty((n_cascade_levels, ar_order))\n",
    "for i in range(n_cascade_levels):\n",
    "    R_c_ = np.stack([R_c[i, j, :, :] for j in range(ar_order + 1)])\n",
    "    GAMMA[i, :] = correlation.temporal_autocorrelation(R_c_, MASK=MASK_thr)\n",
    "R_c_ = None\n",
    "\n",
    "# adjust the lag-2 correlation coefficient to ensure that the AR(p) process is stationary\n",
    "for i in range(n_cascade_levels):\n",
    "    GAMMA[i, 1] = autoregression.adjust_lag2_corrcoef2(GAMMA[i, 0], GAMMA[i, 1])\n",
    "\n",
    "# estimate the parameters of the AR(p) model from the autocorrelation coefficients\n",
    "PHI = np.empty((n_cascade_levels, ar_order + 1))\n",
    "for i in range(n_cascade_levels):\n",
    "    PHI[i, :] = autoregression.estimate_ar_params_yw(GAMMA[i, :])\n",
    "\n",
    "# discard all except the p-1 last cascades because they are not needed for the AR(p) model\n",
    "R_c = R_c[:, -ar_order:, :, :]\n",
    "\n",
    "# stack the cascades into a five-dimensional array containing all ensemble members\n",
    "R_c = np.stack([R_c.copy() for i in range(n_ens_members)])\n",
    "\n",
    "# initialize the random generators\n",
    "randgen_prec = []\n",
    "randgen_motion = []\n",
    "np.random.seed(seed)\n",
    "for j in range(n_ens_members):\n",
    "    rs = np.random.RandomState(seed)\n",
    "    randgen_prec.append(rs)\n",
    "    seed = rs.randint(0, high=1e9)\n",
    "    rs = np.random.RandomState(seed)\n",
    "    randgen_motion.append(rs)\n",
    "    seed = rs.randint(0, high=1e9)\n",
    "\n",
    "init_vel_noise, generate_vel_noise = noise.get_method(vel_pert_method)\n",
    "# initialize the perturbation generators for the motion field\n",
    "vps = []\n",
    "for j in range(n_ens_members):\n",
    "    kwargs = {\"randstate\": randgen_motion[j], \"p_par\": vp_par, \"p_perp\": vp_perp}\n",
    "    vp_ = init_vel_noise(V, 1. / kmperpixel, timestep, **kwargs)\n",
    "    vps.append(vp_)\n",
    "\n",
    "D = [None for j in range(n_ens_members)] # very important, store locations of last time step\n",
    "res = np.zeros(shape = (n_ens_members,V.shape[1], V.shape[2]),dtype = 'float32')\n",
    "\n",
    "MASK_prec = R[-1, :, :] >= R_thr\n",
    "# get mask parameters\n",
    "mask_rim =  10\n",
    "mask_f =  1\n",
    "# initialize the structuring element\n",
    "struct = scipy.ndimage.generate_binary_structure(2, 1)\n",
    "# iterate it to expand it nxn\n",
    "n = mask_f * timestep / kmperpixel\n",
    "struct = scipy.ndimage.iterate_structure(struct, int((n - 1) / 2.))\n",
    "# initialize precip mask for each member\n",
    "MASK_prec = _compute_incremental_mask(MASK_prec, struct, mask_rim)\n",
    "MASK_prec = [MASK_prec.copy() for j in range(n_ens_members)]\n",
    "\n",
    "fft_objs = []\n",
    "for i in range(n_ens_members):\n",
    "    fft_objs.append(utils.get_method(fft_method, shape=R.shape[1:]))\n",
    "\n",
    "R = R[-1, :, :]\n",
    "#print(\"Starting nowcast computation.\")\n",
    "# iterate each time step\n",
    "for t in range(n_timesteps):\n",
    "    sys.stdout.flush()\n",
    "    # iterate each ensemble member\n",
    "    for j in range(n_ens_members):\n",
    "        # generate noise field\n",
    "        EPS = generate_noise(pp, randstate=randgen_prec[j],fft_method=fft_objs[j])\n",
    "        # decompose the noise field into a cascade\n",
    "        EPS = decomp_method(EPS, filter, fft_method=fft_objs[j])\n",
    "\n",
    "        # iterate the AR(p) model for each cascade level\n",
    "        for i in range(n_cascade_levels):\n",
    "            # normalize the noise cascade\n",
    "            EPS_ = (EPS[\"cascade_levels\"][i, :, :] - EPS[\"means\"][i]) / EPS[\"stds\"][i]\n",
    "            EPS_ *= noise_std_coeffs[i]\n",
    "            R_c[j, i, :, :, :] = autoregression.iterate_ar_model(R_c[j, i, :, :, :], PHI[i, :], EPS=EPS_)\n",
    "        del EPS, EPS_ \n",
    "\n",
    "        # compute the recomposed precipitation field(s) from the cascades obtained from the AR(p) model(s)\n",
    "        R_c_ = nowcast_utils.recompose_cascade(R_c[j, :, -1, :, :], mu, sigma)\n",
    "\n",
    "        # apply the precipitation mask to prevent generation of new precipitation into areas where it was not originally observed\n",
    "        R_cmin = R_c_.min()\n",
    "        R_c_ = R_cmin + (R_c_ - R_cmin) * MASK_prec[j]\n",
    "        MASK_prec_ = R_c_ > R_cmin\n",
    "\n",
    "        # Set to min value outside of mask\n",
    "        R_c_[~MASK_prec_] = R_cmin\n",
    "        # adjust the CDF of the forecast to match the most recently observed precipitation field\n",
    "        R_c_ = probmatching.nonparam_match_empirical_cdf(R_c_, R)\n",
    "        MASK_prec[j] = _compute_incremental_mask(R_c_ >= R_thr, struct, mask_rim)\n",
    "\n",
    "        # compute the perturbed motion field\n",
    "        V_ = V + generate_vel_noise(vps[j], (t + 1) * timestep)\n",
    "        # advect the recomposed precipitation field to obtain the forecast for time step t\n",
    "        extrap_kwargs.update({\"D_prev\": D[j], \"return_displacement\": True})\n",
    "        R_f_, D_ = extrapolator_method(R_c_, V_, 1, **extrap_kwargs)\n",
    "        D[j] = D_   # very important for next time step calculation\n",
    "        if t == n_timesteps -1:\n",
    "            res[j] = R_f_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function pysteps.cascade.decomposition.decomposition_fft(field, bp_filter, **kwargs)>,\n",
       " <function pysteps.cascade.decomposition.recompose_fft(decomp, **kwargs)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomp_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
